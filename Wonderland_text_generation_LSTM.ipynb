{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raviintechis/Wonderland_text_generation_LSTM/blob/main/Wonderland_text_generation_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZC2XekiwHFj"
      },
      "source": [
        "##First Program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMksprGtvvTC",
        "outputId": "7d002532-1adb-407c-e86b-9e399a908ade"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhTG8WafKJQX",
        "outputId": "d0e818ee-42d8-435a-d049-0e3f78173007"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "U0K5IbsJbCVk"
      },
      "outputs": [],
      "source": [
        "...\n",
        "# load ascii text and covert to lowercase\n",
        "filename = \"alice_in_wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3-_EGuXrfsBg"
      },
      "outputs": [],
      "source": [
        "...\n",
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcuh56YJfyFL",
        "outputId": "1192adfd-df73-4929-a806-029732367b68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " '\\r',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " '[',\n",
              " ']',\n",
              " '_',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '»',\n",
              " '¿',\n",
              " 'ï']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "['\\n', '\\r', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xbb', '\\xbf', '\\xef']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU313z6Af63P",
        "outputId": "a22a0693-a68c-4579-c5ca-960475f184a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters: \n",
            "Total Vocab: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 46)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "...\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \"), n_chars\n",
        "print (\"Total Vocab: \"), n_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zsk0NQTf_bq",
        "outputId": "b5cd7496-1ab2-44e7-d805-b7871b16393c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 148474)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "...\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \"), n_patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QlVXbVh1gmeS"
      },
      "outputs": [],
      "source": [
        "...\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BR2FhXv1g956"
      },
      "outputs": [],
      "source": [
        "...\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Z9tCMIrmhMcz"
      },
      "outputs": [],
      "source": [
        "...\n",
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkJnPbKGhR1s",
        "outputId": "e0c5a892-78b0-4893-d8d6-2731a9034227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.9454\n",
            "Epoch 00001: loss improved from inf to 2.94538, saving model to weights-improvement-01-2.9454.hdf5\n",
            "1160/1160 [==============================] - 634s 545ms/step - loss: 2.9454\n",
            "Epoch 2/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.7097\n",
            "Epoch 00002: loss improved from 2.94538 to 2.70972, saving model to weights-improvement-02-2.7097.hdf5\n",
            "1160/1160 [==============================] - 623s 537ms/step - loss: 2.7097\n",
            "Epoch 3/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.6049\n",
            "Epoch 00003: loss improved from 2.70972 to 2.60489, saving model to weights-improvement-03-2.6049.hdf5\n",
            "1160/1160 [==============================] - 623s 537ms/step - loss: 2.6049\n",
            "Epoch 4/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.5412\n",
            "Epoch 00004: loss improved from 2.60489 to 2.54122, saving model to weights-improvement-04-2.5412.hdf5\n",
            "1160/1160 [==============================] - 622s 536ms/step - loss: 2.5412\n",
            "Epoch 5/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.4851\n",
            "Epoch 00005: loss improved from 2.54122 to 2.48510, saving model to weights-improvement-05-2.4851.hdf5\n",
            "1160/1160 [==============================] - 623s 537ms/step - loss: 2.4851\n",
            "Epoch 6/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.4318\n",
            "Epoch 00006: loss improved from 2.48510 to 2.43177, saving model to weights-improvement-06-2.4318.hdf5\n",
            "1160/1160 [==============================] - 623s 537ms/step - loss: 2.4318\n",
            "Epoch 7/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.3816\n",
            "Epoch 00007: loss improved from 2.43177 to 2.38163, saving model to weights-improvement-07-2.3816.hdf5\n",
            "1160/1160 [==============================] - 625s 539ms/step - loss: 2.3816\n",
            "Epoch 8/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.3339\n",
            "Epoch 00008: loss improved from 2.38163 to 2.33395, saving model to weights-improvement-08-2.3339.hdf5\n",
            "1160/1160 [==============================] - 629s 542ms/step - loss: 2.3339\n",
            "Epoch 9/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.2933\n",
            "Epoch 00009: loss improved from 2.33395 to 2.29328, saving model to weights-improvement-09-2.2933.hdf5\n",
            "1160/1160 [==============================] - 630s 543ms/step - loss: 2.2933\n",
            "Epoch 10/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.2507\n",
            "Epoch 00010: loss improved from 2.29328 to 2.25070, saving model to weights-improvement-10-2.2507.hdf5\n",
            "1160/1160 [==============================] - 630s 543ms/step - loss: 2.2507\n",
            "Epoch 11/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.2145\n",
            "Epoch 00011: loss improved from 2.25070 to 2.21446, saving model to weights-improvement-11-2.2145.hdf5\n",
            "1160/1160 [==============================] - 628s 541ms/step - loss: 2.2145\n",
            "Epoch 12/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.1748\n",
            "Epoch 00012: loss improved from 2.21446 to 2.17477, saving model to weights-improvement-12-2.1748.hdf5\n",
            "1160/1160 [==============================] - 630s 543ms/step - loss: 2.1748\n",
            "Epoch 13/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.1382\n",
            "Epoch 00013: loss improved from 2.17477 to 2.13816, saving model to weights-improvement-13-2.1382.hdf5\n",
            "1160/1160 [==============================] - 630s 543ms/step - loss: 2.1382\n",
            "Epoch 14/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.1195\n",
            "Epoch 00014: loss improved from 2.13816 to 2.11948, saving model to weights-improvement-14-2.1195.hdf5\n",
            "1160/1160 [==============================] - 630s 543ms/step - loss: 2.1195\n",
            "Epoch 15/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.0755\n",
            "Epoch 00015: loss improved from 2.11948 to 2.07550, saving model to weights-improvement-15-2.0755.hdf5\n",
            "1160/1160 [==============================] - 628s 541ms/step - loss: 2.0755\n",
            "Epoch 16/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.0483\n",
            "Epoch 00016: loss improved from 2.07550 to 2.04832, saving model to weights-improvement-16-2.0483.hdf5\n",
            "1160/1160 [==============================] - 629s 543ms/step - loss: 2.0483\n",
            "Epoch 17/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 2.0195\n",
            "Epoch 00017: loss improved from 2.04832 to 2.01950, saving model to weights-improvement-17-2.0195.hdf5\n",
            "1160/1160 [==============================] - 630s 543ms/step - loss: 2.0195\n",
            "Epoch 18/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 1.9941\n",
            "Epoch 00018: loss improved from 2.01950 to 1.99414, saving model to weights-improvement-18-1.9941.hdf5\n",
            "1160/1160 [==============================] - 633s 546ms/step - loss: 1.9941\n",
            "Epoch 19/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 1.9686\n",
            "Epoch 00019: loss improved from 1.99414 to 1.96862, saving model to weights-improvement-19-1.9686.hdf5\n",
            "1160/1160 [==============================] - 633s 546ms/step - loss: 1.9686\n",
            "Epoch 20/20\n",
            "1160/1160 [==============================] - ETA: 0s - loss: 1.9412\n",
            "Epoch 00020: loss improved from 1.96862 to 1.94117, saving model to weights-improvement-20-1.9412.hdf5\n",
            "1160/1160 [==============================] - 631s 544ms/step - loss: 1.9412\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5570d4e750>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "T7Sl-tgnhVWV"
      },
      "outputs": [],
      "source": [
        "...\n",
        "# load the network weights\n",
        "filename = \"weights-improvement-20-1.9412.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "...\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "ApL8NDNPCLL8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "dTZaDoZGEB8e"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "...\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVVTtEKICTx7",
        "outputId": "f7601773-0492-4acb-df71-b8cbf8c120ef"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" opping herself before she found herself\n",
            "falling down a very deep well.\n",
            "\n",
            "  either the well was very d \"\n",
            "arten, and then she had not aeret a latge call wfsh the cade                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_ynwvVniD2gu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Wonderland_text_generation_LSTM.ipynb",
      "provenance": [],
      "mount_file_id": "12Ar5VcW8ilSWHcKd7Qc8gRPEleC4K0Zy",
      "authorship_tag": "ABX9TyNPkCrlz5nIgg1nmQM5y9i6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}